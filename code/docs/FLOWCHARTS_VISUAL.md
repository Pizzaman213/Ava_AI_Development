# Ava LLM Training Framework - Visual Flowcharts ğŸ¨

Beautiful, color-coded flowcharts for the Ava training system.

---

## Training Lifecycle ğŸš€

### Complete Training Flow

```mermaid
graph TD
    A[ğŸš€ Start Training] --> B[ğŸ“‹ Load Configuration]
    B --> C[ğŸ’¾ Initialize Data Pipeline]
    C --> D[ğŸ§  Initialize Model]
    D --> E[âš™ï¸ Initialize Optimizer]
    E --> F[ğŸ”¥ Warmup Phase]
    F --> G[ğŸ”„ Training Loop]

    G --> H[ğŸ“¦ Get Batch]
    H --> I[â¡ï¸ Forward Pass]
    I --> J[ğŸ“Š Compute Loss]
    J --> K[â¬…ï¸ Backward Pass]
    K --> L[âœ‚ï¸ Clip Gradients]
    L --> M[ğŸ”§ Optimizer Step]
    M --> N[ğŸ“ˆ Update Learning Rate]

    N --> O{ğŸ” Eval Step?}
    O -->|Yes| P[âœ… Run Evaluation]
    O -->|No| Q{ğŸ’¾ Save Step?}
    P --> Q

    Q -->|Yes| R[ğŸ’¾ Save Checkpoint]
    Q -->|No| S{â“ More Steps?}
    R --> S

    S -->|Yes| G
    S -->|No| T[ğŸ“Š Final Evaluation]
    T --> U[ğŸ’¾ Save Final Model]
    U --> V[ğŸ‰ Training Complete]

    style A fill:#4CAF50,stroke:#2E7D32,stroke-width:3px,color:#fff
    style V fill:#4CAF50,stroke:#2E7D32,stroke-width:3px,color:#fff
    style G fill:#2196F3,stroke:#1565C0,stroke-width:3px,color:#fff
    style I fill:#FF9800,stroke:#E65100,stroke-width:2px,color:#fff
    style K fill:#FF9800,stroke:#E65100,stroke-width:2px,color:#fff
    style P fill:#9C27B0,stroke:#6A1B9A,stroke-width:2px,color:#fff
    style R fill:#00BCD4,stroke:#006064,stroke-width:2px,color:#fff
```

### Single Training Step Detail

```mermaid
graph LR
    A[ğŸ“¦ Input Batch] --> B[â¡ï¸ Forward Pass]
    B --> C[ğŸ“Š Loss Computation]
    C --> D[â¬…ï¸ Backward Pass]
    D --> E[ğŸ“‰ Gradients]
    E --> F[âœ‚ï¸ Gradient Clipping]
    F --> G[ğŸ”§ Optimization]
    G --> H[âœ¨ Parameter Update]

    style A fill:#E3F2FD,stroke:#2196F3,stroke-width:2px
    style B fill:#FFF3E0,stroke:#FF9800,stroke-width:2px
    style C fill:#FCE4EC,stroke:#E91E63,stroke-width:2px
    style D fill:#F3E5F5,stroke:#9C27B0,stroke-width:2px
    style E fill:#E8F5E9,stroke:#4CAF50,stroke-width:2px
    style F fill:#FFF9C4,stroke:#FBC02D,stroke-width:2px
    style G fill:#E0F2F1,stroke:#009688,stroke-width:2px
    style H fill:#C8E6C9,stroke:#388E3C,stroke-width:3px
```

---

## Model Architecture ğŸ§ 

### Transformer Layer Flow

```mermaid
graph TD
    A[ğŸ¯ Input: BÃ—LÃ—H] --> B[ğŸ”„ Layer Norm 1]
    B --> C[ğŸ‘ï¸ Multi-Head Attention]
    C --> D[â• Residual Connection]
    D --> E[ğŸ”„ Layer Norm 2]
    E --> F[ğŸ¯ MoE Router]

    F --> G[âš¡ Expert 1]
    F --> H[âš¡ Expert 2]
    F --> I[âš¡ Expert 3]
    F --> J[âš¡ Expert 8]

    G --> K[ğŸ¨ Weighted Combine]
    H --> K
    I --> K
    J --> K

    K --> L[â• Residual Connection]
    L --> M[âœ¨ Output: BÃ—LÃ—H]

    style A fill:#E3F2FD,stroke:#2196F3,stroke-width:3px
    style C fill:#FFF3E0,stroke:#FF9800,stroke-width:2px
    style F fill:#FCE4EC,stroke:#E91E63,stroke-width:3px
    style G fill:#E8F5E9,stroke:#4CAF50,stroke-width:2px
    style H fill:#E8F5E9,stroke:#4CAF50,stroke-width:2px
    style I fill:#E8F5E9,stroke:#4CAF50,stroke-width:2px
    style J fill:#E8F5E9,stroke:#4CAF50,stroke-width:2px
    style K fill:#F3E5F5,stroke:#9C27B0,stroke-width:3px
    style M fill:#C8E6C9,stroke:#388E3C,stroke-width:3px
```

### Attention Mechanism Flow

```mermaid
graph LR
    A[ğŸ“¥ Hidden States] --> B[ğŸ”€ Split Q, K, V]
    B --> C[ğŸ”„ Apply RoPE]
    C --> D[âœ–ï¸ Q @ K^T]
    D --> E[ğŸ“ Scale by âˆšd]
    E --> F[ğŸ­ Apply Mask]
    F --> G[ğŸ“Š Softmax]
    G --> H[âœ–ï¸ @ Values]
    H --> I[ğŸ”— Concat Heads]
    I --> J[ğŸ“¤ Output Projection]

    style A fill:#E3F2FD,stroke:#2196F3,stroke-width:2px
    style B fill:#FFF3E0,stroke:#FF9800,stroke-width:2px
    style C fill:#FCE4EC,stroke:#E91E63,stroke-width:2px
    style D fill:#F3E5F5,stroke:#9C27B0,stroke-width:2px
    style G fill:#FFE082,stroke:#F57C00,stroke-width:3px
    style J fill:#C8E6C9,stroke:#388E3C,stroke-width:3px
```

---

## Expert Routing ğŸ¯

### MoE Router Decision Flow

```mermaid
graph TD
    A[ğŸ¯ Token Hidden State] --> B[ğŸ”¢ Router Linear Layer]
    B --> C[ğŸ² Add Jitter Noise]
    C --> D[ğŸ“Š Softmax Normalization]
    D --> E[ğŸ† Top-K Selection K=2]

    E --> F[âš¡ Expert 1: pâ‚]
    E --> G[âš¡ Expert 2: pâ‚‚]

    F --> H{ğŸ” Capacity OK?}
    H -->|âœ… Yes| I[âœ¨ Route to Expert 1]
    H -->|âŒ Full| J[âš ï¸ Overflow Handler]

    G --> K{ğŸ” Capacity OK?}
    K -->|âœ… Yes| L[âœ¨ Route to Expert 2]
    K -->|âŒ Full| M[âš ï¸ Overflow Handler]

    J --> N[ğŸ”„ Try Next Best]
    M --> O[ğŸ”„ Try Next Best]

    I --> P[ğŸ¨ Weighted Sum]
    L --> P
    N --> P
    O --> P

    P --> Q[âœ¨ Final Output]

    style A fill:#E3F2FD,stroke:#2196F3,stroke-width:3px
    style D fill:#FFF3E0,stroke:#FF9800,stroke-width:2px
    style E fill:#FCE4EC,stroke:#E91E63,stroke-width:3px
    style I fill:#C8E6C9,stroke:#388E3C,stroke-width:2px
    style L fill:#C8E6C9,stroke:#388E3C,stroke-width:2px
    style J fill:#FFCCBC,stroke:#D84315,stroke-width:2px
    style M fill:#FFCCBC,stroke:#D84315,stroke-width:2px
    style P fill:#F3E5F5,stroke:#9C27B0,stroke-width:3px
    style Q fill:#80DEEA,stroke:#00838F,stroke-width:3px
```

### Load Balancing Flow

```mermaid
graph LR
    A[ğŸ“Š Router Probs] --> B[ğŸ“ˆ Compute Expert Fractions]
    B --> C[ğŸ“Š Compute Avg Probs]
    C --> D[âš–ï¸ Balance Loss]
    D --> E[â• Add to Total Loss]
    E --> F[â¬…ï¸ Backprop]
    F --> G[ğŸ”„ Update Router Weights]
    G --> H[âœ¨ Balanced Routing]

    style A fill:#E3F2FD,stroke:#2196F3,stroke-width:2px
    style B fill:#FFF3E0,stroke:#FF9800,stroke-width:2px
    style C fill:#FCE4EC,stroke:#E91E63,stroke-width:2px
    style D fill:#F3E5F5,stroke:#9C27B0,stroke-width:3px
    style F fill:#FFCCBC,stroke:#D84315,stroke-width:2px
    style G fill:#C8E6C9,stroke:#388E3C,stroke-width:2px
    style H fill:#80DEEA,stroke:#00838F,stroke-width:3px
```

---

## Gradient Flow ğŸ“‰

### Backward Pass and Update

```mermaid
graph TD
    A[ğŸ“Š Loss Computed] --> B{â“ Loss Valid?}
    B -->|âŒ NaN/Inf| C[â­ï¸ Skip Step]
    B -->|âœ… Valid| D[â¬…ï¸ Backward Pass]

    D --> E[ğŸ“‰ Compute Gradients]
    E --> F{â“ Gradients Valid?}
    F -->|âŒ NaN/Inf| C
    F -->|âœ… Valid| G[ğŸ“ Compute Grad Norm]

    G --> H{â“ Norm > Threshold?}
    H -->|âš ï¸ Explosion| I[ğŸ”» Reduce LR]
    H -->|âœ… Healthy| J[âœ‚ï¸ Clip Gradients]
    I --> J

    J --> K{ğŸŒ Distributed?}
    K -->|Yes| L[ğŸ”„ All-Reduce Gradients]
    K -->|No| M[ğŸ”§ Optimizer Step]
    L --> M

    M --> N[âœ¨ Update Parameters]
    N --> O[ğŸ“ˆ Scheduler Step]
    O --> P[ğŸ¯ Update LR]

    style A fill:#E3F2FD,stroke:#2196F3,stroke-width:2px
    style C fill:#FFCDD2,stroke:#C62828,stroke-width:2px,color:#000
    style D fill:#FFF3E0,stroke:#FF9800,stroke-width:3px
    style E fill:#F3E5F5,stroke:#9C27B0,stroke-width:2px
    style I fill:#FFCCBC,stroke:#D84315,stroke-width:2px
    style J fill:#FFF9C4,stroke:#F57C00,stroke-width:2px
    style L fill:#E0F2F1,stroke:#00897B,stroke-width:2px
    style M fill:#C8E6C9,stroke:#388E3C,stroke-width:3px
    style N fill:#80DEEA,stroke:#00838F,stroke-width:3px
```

### Gradient Health Monitor

```mermaid
graph LR
    A[ğŸ“‰ Gradients] --> B[ğŸ“ Compute Norm]
    B --> C{ğŸ” Health Check}
    C -->|ğŸ’¥ Explosion| D[ğŸ“ˆ Counter++]
    C -->|âœ… Healthy| E[ğŸ”„ Reset Counter]
    D --> F{â“ Counter > Window?}
    F -->|âš ï¸ Yes| G[ğŸš¨ Emergency LR Reduce]
    F -->|No| H[âœ… Continue]
    E --> H
    G --> H

    style A fill:#E3F2FD,stroke:#2196F3,stroke-width:2px
    style C fill:#FFF3E0,stroke:#FF9800,stroke-width:3px
    style D fill:#FFCCBC,stroke:#D84315,stroke-width:2px
    style E fill:#C8E6C9,stroke:#388E3C,stroke-width:2px
    style G fill:#EF5350,stroke:#B71C1C,stroke-width:3px,color:#fff
    style H fill:#80DEEA,stroke:#00838F,stroke-width:2px
```

---

## Memory Management ğŸ’¾

### GPU Memory Monitoring

```mermaid
graph TD
    A[ğŸ” Check GPU Memory] --> B[ğŸ“Š Compute Utilization]
    B --> C{ğŸ“ˆ Utilization Level?}

    C -->|< 75%| D[âœ… Normal: Continue]
    C -->|75-80%| E[âš ï¸ Warning: Log Alert]
    C -->|80-85%| F[ğŸŸ  Critical: Prepare Action]
    C -->|85-90%| G[ğŸ”´ Emergency: Clear Cache]
    C -->|> 90%| H[ğŸ’¥ Crisis: Reduce Batch]

    E --> D
    F --> I[ğŸ“‰ Reduce Batch 25%]
    I --> D
    G --> J[ğŸ§¹ torch.cuda.empty_cache]
    J --> K[ğŸ“‰ Reduce Batch 50%]
    K --> D
    H --> L[ğŸ’¾ Save Emergency Checkpoint]
    L --> M[âš™ï¸ Set Min Batch Size]
    M --> N[ğŸš¨ Raise OOM Error]

    style A fill:#E3F2FD,stroke:#2196F3,stroke-width:2px
    style D fill:#C8E6C9,stroke:#388E3C,stroke-width:3px
    style E fill:#FFF9C4,stroke:#F57C00,stroke-width:2px
    style F fill:#FFCC80,stroke:#EF6C00,stroke-width:2px
    style G fill:#FFAB91,stroke:#D84315,stroke-width:2px
    style H fill:#EF5350,stroke:#B71C1C,stroke-width:3px,color:#fff
    style N fill:#000,stroke:#000,stroke-width:3px,color:#fff
```

### OOM Recovery Strategy

```mermaid
graph LR
    A[ğŸ’¥ OOM Error] --> B[âœ‚ï¸ Enable Grad Checkpoint]
    B --> C{âœ… Works?}
    C -->|No| D[ğŸ“‰ Reduce Batch Size]
    C -->|Yes| E[ğŸ‰ Continue Training]
    D --> F{âœ… Works?}
    F -->|No| G[ğŸ”§ Enable ZeRO-2]
    F -->|Yes| E
    G --> H{âœ… Works?}
    H -->|No| I[ğŸ’¾ Enable CPU Offload]
    H -->|Yes| E
    I --> J{âœ… Works?}
    J -->|No| K[ğŸ’€ Fatal Error]
    J -->|Yes| E

    style A fill:#EF5350,stroke:#B71C1C,stroke-width:3px,color:#fff
    style B fill:#FFF3E0,stroke:#FF9800,stroke-width:2px
    style D fill:#FFCC80,stroke:#EF6C00,stroke-width:2px
    style G fill:#CE93D8,stroke:#8E24AA,stroke-width:2px
    style I fill:#90CAF9,stroke:#1565C0,stroke-width:2px
    style E fill:#81C784,stroke:#388E3C,stroke-width:3px
    style K fill:#000,stroke:#000,stroke-width:3px,color:#fff
```

---

## Checkpoint Management ğŸ’¾

### Save Checkpoint Flow

```mermaid
graph TD
    A[ğŸ’¾ Save Trigger] --> B{ğŸ” Rank 0?}
    B -->|No| C[â³ Wait at Barrier]
    B -->|Yes| D[ğŸ“¦ Create Checkpoint Dict]

    D --> E[ğŸ§  Add Model State]
    E --> F[âš™ï¸ Add Optimizer State]
    F --> G[ğŸ“ˆ Add Scheduler State]
    G --> H[ğŸ“Š Add Metrics]
    H --> I[ğŸ² Add RNG States]

    I --> J[ğŸ’¾ Write to Disk]
    J --> K[ğŸ”— Update 'latest' Link]
    K --> L{ğŸ† Is Best Model?}
    L -->|Yes| M[â­ Update 'best' Link]
    L -->|No| N[ğŸ”„ Sync Barrier]
    M --> N

    C --> N
    N --> O[âœ… Save Complete]

    style A fill:#E3F2FD,stroke:#2196F3,stroke-width:3px
    style D fill:#FFF3E0,stroke:#FF9800,stroke-width:2px
    style J fill:#F3E5F5,stroke:#9C27B0,stroke-width:2px
    style M fill:#FFD54F,stroke:#F57C00,stroke-width:3px
    style O fill:#81C784,stroke:#388E3C,stroke-width:3px
```

### Load Checkpoint Flow

```mermaid
graph TD
    A[ğŸ“‚ Load Request] --> B{â“ Path Valid?}
    B -->|No| C[ğŸ” Search for 'latest']
    B -->|Yes| D[ğŸ“– Read File]
    C --> D

    D --> E{âœ… Valid Checkpoint?}
    E -->|No| F[âŒ Load Error]
    E -->|Yes| G[ğŸ§  Load Model State]

    G --> H{âœ… Success?}
    H -->|No| F
    H -->|Yes| I[âš™ï¸ Load Optimizer State]

    I --> J[ğŸ“ˆ Load Scheduler State]
    J --> K[ğŸ² Restore RNG States]
    K --> L[ğŸ“Š Extract Metrics]
    L --> M[âœ¨ Load Complete]

    style A fill:#E3F2FD,stroke:#2196F3,stroke-width:3px
    style F fill:#EF5350,stroke:#B71C1C,stroke-width:3px,color:#fff
    style G fill:#FFF3E0,stroke:#FF9800,stroke-width:2px
    style I fill:#F3E5F5,stroke:#9C27B0,stroke-width:2px
    style M fill:#81C784,stroke:#388E3C,stroke-width:3px
```

---

## Data Pipeline ğŸ“Š

### Data Processing Flow

```mermaid
graph LR
    A[ğŸ“ Raw Files] --> B[ğŸ” Format Detection]
    B --> C[ğŸ“– Load Data]
    C --> D[âœ… Validation]
    D --> E[ğŸ”¬ Quality Filters]
    E --> F[ğŸ”¤ Tokenization]
    F --> G[ğŸ“¦ Batching]
    G --> H[ğŸ”„ DataLoader]

    style A fill:#E3F2FD,stroke:#2196F3,stroke-width:2px
    style B fill:#FFF3E0,stroke:#FF9800,stroke-width:2px
    style C fill:#FCE4EC,stroke:#E91E63,stroke-width:2px
    style D fill:#F3E5F5,stroke:#9C27B0,stroke-width:2px
    style E fill:#E8F5E9,stroke:#4CAF50,stroke-width:2px
    style F fill:#FFF9C4,stroke:#FBC02D,stroke-width:2px
    style G fill:#E0F2F1,stroke:#009688,stroke-width:2px
    style H fill:#C8E6C9,stroke:#388E3C,stroke-width:3px
```

### Format Detection

```mermaid
graph TD
    A[ğŸ“„ Data File] --> B[ğŸ” Sample Lines]
    B --> C[ğŸ“‹ Try JSONL]
    B --> D[ğŸ—‚ï¸ Try Arrow]
    B --> E[ğŸ“Š Try Parquet]

    C --> F[ğŸ“Š Score Confidence]
    D --> F
    E --> F

    F --> G[ğŸ¯ Select Best Format]
    G --> H[âœ¨ Load with Format]

    style A fill:#E3F2FD,stroke:#2196F3,stroke-width:3px
    style C fill:#FFF3E0,stroke:#FF9800,stroke-width:2px
    style D fill:#FCE4EC,stroke:#E91E63,stroke-width:2px
    style E fill:#F3E5F5,stroke:#9C27B0,stroke-width:2px
    style G fill:#FFD54F,stroke:#F57C00,stroke-width:3px
    style H fill:#81C784,stroke:#388E3C,stroke-width:3px
```

---

## Adaptive Learning Rate ğŸ“ˆ

### LR Adjustment Flow

```mermaid
graph TD
    A[ğŸ”„ Training Step] --> B{â±ï¸ Check Interval?}
    B -->|No| C[âœ… Continue]
    B -->|Yes| D[ğŸ“Š Compute Loss Window]

    D --> E{ğŸ“ˆ Improvement?}
    E -->|Yes| F[â­ Update Best Loss]
    E -->|No| G[ğŸ“‰ Increment Plateau Counter]

    F --> H[ğŸ”„ Reset Counter]
    H --> C

    G --> I{â³ Counter > Patience?}
    I -->|No| C
    I -->|Yes| J{ğŸ” Gradients Stable?}

    J -->|Yes| K[ğŸš€ Boost LR +15%]
    J -->|No| L[ğŸ”» Reduce LR -30%]

    K --> M[âœ¨ Apply New LR]
    L --> M
    M --> N[ğŸ”„ Reset Counter]
    N --> C

    style A fill:#E3F2FD,stroke:#2196F3,stroke-width:2px
    style F fill:#81C784,stroke:#388E3C,stroke-width:2px
    style G fill:#FFCC80,stroke:#EF6C00,stroke-width:2px
    style K fill:#66BB6A,stroke:#2E7D32,stroke-width:3px
    style L fill:#EF5350,stroke:#B71C1C,stroke-width:3px,color:#fff
    style C fill:#80DEEA,stroke:#00838F,stroke-width:2px
```

### LR Schedule Visualization

```mermaid
graph LR
    A[ğŸ“ Step 0] --> B[ğŸ”¥ Warmup Phase]
    B --> C[ğŸ¯ Peak LR]
    C --> D[ğŸ“‰ Cosine Decay]
    D --> E[ğŸ”„ Restart 1]
    E --> F[ğŸ¯ Peak LR]
    F --> G[ğŸ“‰ Cosine Decay]
    G --> H[ğŸ Final LR]

    style A fill:#E3F2FD,stroke:#2196F3,stroke-width:2px
    style B fill:#FFAB91,stroke:#D84315,stroke-width:2px
    style C fill:#FFD54F,stroke:#F57C00,stroke-width:3px
    style D fill:#90CAF9,stroke:#1565C0,stroke-width:2px
    style E fill:#CE93D8,stroke:#8E24AA,stroke-width:2px
    style F fill:#FFD54F,stroke:#F57C00,stroke-width:3px
    style G fill:#90CAF9,stroke:#1565C0,stroke-width:2px
    style H fill:#81C784,stroke:#388E3C,stroke-width:3px
```

---

## RLHF Training ğŸ¤–

### PPO Training Loop

```mermaid
graph TD
    A[ğŸš€ Start RLHF] --> B[ğŸ§  Load Policy Model]
    B --> C[ğŸ Load Reward Model]
    C --> D[ğŸ”„ For Each Epoch]

    D --> E[ğŸ“ Sample Prompts]
    E --> F[âœ¨ Generate Responses]
    F --> G[ğŸ Compute Rewards]
    G --> H[ğŸ“Š Compute Advantages]

    H --> I[ğŸ”„ PPO Update Loop]
    I --> J[ğŸ“ Compute Ratio Ï€_new/Ï€_old]
    J --> K[âœ‚ï¸ Clip Ratio Îµ=0.2]
    K --> L[ğŸ“‰ Policy Loss]
    L --> M[ğŸ“Š Value Loss]
    M --> N[â• Total Loss]

    N --> O[â¬…ï¸ Backward]
    O --> P[ğŸ”§ Optimizer Step]
    P --> Q{ğŸ” KL < Threshold?}

    Q -->|No| R[âš™ï¸ Adjust KL Penalty]
    Q -->|Yes| S{â“ More Updates?}
    R --> S

    S -->|Yes| I
    S -->|No| T{â“ More Epochs?}
    T -->|Yes| D
    T -->|No| U[ğŸ’¾ Save Final Model]

    style A fill:#4CAF50,stroke:#2E7D32,stroke-width:3px,color:#fff
    style F fill:#FFF3E0,stroke:#FF9800,stroke-width:2px
    style G fill:#F3E5F5,stroke:#9C27B0,stroke-width:2px
    style I fill:#2196F3,stroke:#1565C0,stroke-width:3px,color:#fff
    style K fill:#FFCC80,stroke:#EF6C00,stroke-width:2px
    style U fill:#81C784,stroke:#388E3C,stroke-width:3px
```

---

## Evaluation & Testing âœ…

### Evaluation Flow

```mermaid
graph LR
    A[ğŸ”” Eval Trigger] --> B[ğŸ¯ Set Eval Mode]
    B --> C[ğŸš« Disable Dropout]
    C --> D[ğŸ”„ For Each Val Batch]
    D --> E[â¡ï¸ Forward Pass]
    E --> F[ğŸ“Š Compute Loss]
    F --> G[ğŸ“ˆ Accumulate Metrics]
    G --> H{â“ More Batches?}
    H -->|Yes| D
    H -->|No| I[ğŸ“Š Compute Averages]
    I --> J[ğŸ“ Log Metrics]
    J --> K[ğŸ”„ Set Train Mode]

    style A fill:#E3F2FD,stroke:#2196F3,stroke-width:3px
    style B fill:#FFF3E0,stroke:#FF9800,stroke-width:2px
    style E fill:#FCE4EC,stroke:#E91E63,stroke-width:2px
    style I fill:#F3E5F5,stroke:#9C27B0,stroke-width:2px
    style K fill:#81C784,stroke:#388E3C,stroke-width:3px
```

### Generation Quality Testing

```mermaid
graph TD
    A[ğŸ“ Test Prompts] --> B[âœ¨ Generate Responses]
    B --> C[ğŸ“Š Compute Perplexity]
    B --> D[ğŸ¨ Compute Distinct-2]
    B --> E[ğŸ§  Compute Coherence]
    B --> F[ğŸ” Compute Repetition Rate]

    C --> G[ğŸ“ˆ Aggregate Metrics]
    D --> G
    E --> G
    F --> G

    G --> H{âœ… Quality Good?}
    H -->|Yes| I[ğŸ‰ Continue Training]
    H -->|No| J[âš™ï¸ Adjust Hyperparams]
    J --> I

    style A fill:#E3F2FD,stroke:#2196F3,stroke-width:3px
    style B fill:#FFF3E0,stroke:#FF9800,stroke-width:2px
    style C fill:#FCE4EC,stroke:#E91E63,stroke-width:2px
    style D fill:#F3E5F5,stroke:#9C27B0,stroke-width:2px
    style E fill:#E8F5E9,stroke:#4CAF50,stroke-width:2px
    style F fill:#FFF9C4,stroke:#FBC02D,stroke-width:2px
    style G fill:#E0F2F1,stroke:#009688,stroke-width:2px
    style H fill:#FFCC80,stroke:#EF6C00,stroke-width:3px
    style I fill:#81C784,stroke:#388E3C,stroke-width:3px
    style J fill:#FFAB91,stroke:#D84315,stroke-width:2px
```

---

## Multi-GPU Training ğŸŒ

### Distributed Training Flow

```mermaid
graph LR
    A[ğŸ® Rank 0] --> E[ğŸ”„ Broadcast Params]
    B[ğŸ® Rank 1] --> E
    C[ğŸ® Rank 2] --> E
    D[ğŸ® Rank 3] --> E

    E --> F[â¡ï¸ Forward Pass All]
    F --> G[â¬…ï¸ Backward Pass All]
    G --> H[ğŸ”„ All-Reduce Gradients]
    H --> I[ğŸ”§ Optimizer Step All]
    I --> J[âœ¨ Synchronized Parameters]

    style A fill:#E3F2FD,stroke:#2196F3,stroke-width:2px
    style B fill:#FFF3E0,stroke:#FF9800,stroke-width:2px
    style C fill:#FCE4EC,stroke:#E91E63,stroke-width:2px
    style D fill:#F3E5F5,stroke:#9C27B0,stroke-width:2px
    style E fill:#FFCC80,stroke:#EF6C00,stroke-width:3px
    style H fill:#90CAF9,stroke:#1565C0,stroke-width:3px
    style J fill:#81C784,stroke:#388E3C,stroke-width:3px
```

### DeepSpeed ZeRO Stages

```mermaid
graph TD
    A[ğŸ“Š Standard DP] --> B[ğŸ’¾ All GPUs: Full Model Copy]

    C[âš¡ ZeRO-1] --> D[ğŸ”§ Shard Optimizer States]

    E[âš¡ ZeRO-2] --> F[ğŸ”§ Shard Optimizer + Gradients]

    G[âš¡ ZeRO-3] --> H[ğŸ”§ Shard All States]

    B --> I[ğŸ”´ High Memory Usage]
    D --> J[ğŸŸ¡ Lower Memory]
    F --> K[ğŸŸ¢ Even Lower Memory]
    H --> L[ğŸŸ¢ Lowest Memory]

    style A fill:#FFCDD2,stroke:#C62828,stroke-width:2px
    style C fill:#FFF9C4,stroke:#F57C00,stroke-width:2px
    style E fill:#C8E6C9,stroke:#388E3C,stroke-width:2px
    style G fill:#80DEEA,stroke:#00838F,stroke-width:2px
    style I fill:#EF5350,stroke:#B71C1C,stroke-width:2px,color:#fff
    style J fill:#FFD54F,stroke:#F57C00,stroke-width:2px
    style K fill:#81C784,stroke:#388E3C,stroke-width:2px
    style L fill:#4DD0E1,stroke:#00838F,stroke-width:3px
```

---

## Error Recovery ğŸš¨

### Error Handling Flow

```mermaid
graph TD
    A[âš ï¸ Error Detected] --> B{ğŸ” Error Type?}

    B -->|ğŸ’¥ NaN Loss| C[â­ï¸ Skip Step & Log]
    B -->|ğŸ“ˆ Grad Explosion| D[ğŸ”» Reduce LR & Clip]
    B -->|ğŸ’¾ OOM| E[ğŸ§¹ Clear Cache & Reduce Batch]
    B -->|ğŸ“ Data Error| F[â­ï¸ Skip File & Continue]
    B -->|ğŸŒ Network Error| G[ğŸ”„ Retry Connection]

    C --> H{ğŸ“Š Frequency?}
    D --> H
    E --> H
    F --> H
    G --> H

    H -->|ğŸŸ¢ Rare| I[âœ… Resume Training]
    H -->|ğŸ”´ Frequent| J[âš™ï¸ Adjust Config]
    J --> I

    style A fill:#EF5350,stroke:#B71C1C,stroke-width:3px,color:#fff
    style C fill:#FFCC80,stroke:#EF6C00,stroke-width:2px
    style D fill:#FFAB91,stroke:#D84315,stroke-width:2px
    style E fill:#CE93D8,stroke:#8E24AA,stroke-width:2px
    style F fill:#90CAF9,stroke:#1565C0,stroke-width:2px
    style G fill:#80CBC4,stroke:#00695C,stroke-width:2px
    style I fill:#81C784,stroke:#388E3C,stroke-width:3px
```

---

## Legend ğŸ“–

### Color Coding System

```mermaid
graph LR
    A[ğŸ”µ Input/Start] --> B[ğŸŸ  Processing]
    B --> C[ğŸŸ£ Computation]
    C --> D[ğŸŸ¢ Success/Output]

    E[ğŸŸ¡ Warning] --> F[ğŸ”´ Critical/Error]

    style A fill:#E3F2FD,stroke:#2196F3,stroke-width:2px
    style B fill:#FFF3E0,stroke:#FF9800,stroke-width:2px
    style C fill:#F3E5F5,stroke:#9C27B0,stroke-width:2px
    style D fill:#C8E6C9,stroke:#388E3C,stroke-width:3px
    style E fill:#FFF9C4,stroke:#F57C00,stroke-width:2px
    style F fill:#FFCDD2,stroke:#C62828,stroke-width:2px
```

### Icon Legend

- ğŸš€ Start/Launch
- ğŸ”„ Loop/Cycle
- âœ… Success/Complete
- âŒ Error/Failure
- âš ï¸ Warning
- ğŸ“Š Metrics/Data
- ğŸ§  Model/Intelligence
- âš™ï¸ Settings/Config
- ğŸ’¾ Storage/Memory
- ğŸ” Check/Verify
- âœ¨ Output/Result
- ğŸ¯ Target/Goal
- ğŸ“ˆ Increase/Up
- ğŸ“‰ Decrease/Down
- ğŸ”§ Tool/Optimization
- âš¡ Fast/Expert
- ğŸ¨ Combination
- ğŸ’¥ Explosion/Critical
- ğŸŒ Network/Distributed

---

## Summary

These beautiful, color-coded flowcharts provide clear visualizations of all major Ava training framework components with an intuitive color scheme:

- **Blue** ğŸ”µ: Input, initialization, and starting points
- **Orange** ğŸŸ : Processing and transformation steps
- **Purple** ğŸŸ£: Computation and analysis
- **Green** ğŸŸ¢: Success, completion, and outputs
- **Yellow** ğŸŸ¡: Warnings and attention points
- **Red** ğŸ”´: Errors and critical situations

Each flowchart uses emojis for quick visual recognition and makes complex training workflows easy to understand at a glance! ğŸ‰
