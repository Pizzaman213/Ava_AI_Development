# 04 - Loss Functions Guide

**Comprehensive Guide to Ava's Unified Loss System**

---

## Table of Contents

1. [Overview](#overview)
2. [Loss Hierarchy & Architecture](#loss-hierarchy--architecture)
3. [Primary Loss Types](#primary-loss-types)
4. [Loss Components](#loss-components)
5. [UnifiedLoss Composition](#unifiedloss-composition)
6. [Loss Computation Flow](#loss-computation-flow)
7. [Configuration Guide](#configuration-guide)
8. [Use Cases & Examples](#use-cases--examples)
9. [Performance Considerations](#performance-considerations)
10. [Troubleshooting](#troubleshooting)

---

## Overview

Ava's loss system is built around a **unified, modular architecture** that combines multiple loss components into a single, efficient loss function. All loss classes are consolidated in [code/src/Ava/losses/losses.py](../src/Ava/losses/losses.py).

### Key Features

- üéØ **Three primary loss types**: Standard CE, DeepSeek-style, Adaptive MTP
- üß© **Modular components**: Enable/disable features independently
- ‚ö° **Performance optimized**: Minimal overhead (~5-10% vs standard CE)
- üîß **Highly configurable**: 20+ tunable parameters
- üìä **Detailed breakdown**: Monitor individual component contributions
- üöÄ **Distributed-ready**: Compatible with DDP, FSDP, DeepSpeed

---

## Loss Hierarchy & Architecture

### Overall System Architecture

```mermaid
graph TB
    subgraph "Unified Loss System"
        UL[UnifiedLoss<br/>Main Interface]

        subgraph "Primary Loss Selection"
            STD[Standard CE<br/>Simple & Fast]
            DS[DeepSeek Loss<br/>‚≠ê Recommended]
            AMTP[Adaptive MTP<br/>Confidence-Weighted]
        end

        subgraph "Optional Components"
            MTP[Multi-Token<br/>Prediction]
            NGRAM[N-gram<br/>Penalty]
            IMMED[Immediate<br/>Repetition]
            MOE[MoE Load<br/>Balancing]
            ADV[Advanced Losses<br/>Focal/Diversity/etc]
        end

        subgraph "Output"
            TOTAL[Total Loss<br/>Weighted Sum]
            DETAIL[Detailed Breakdown<br/>Per Component]
        end
    end

    UL --> STD
    UL --> DS
    UL --> AMTP
    UL --> MTP
    UL --> NGRAM
    UL --> IMMED
    UL --> MOE
    UL --> ADV

    STD --> TOTAL
    DS --> TOTAL
    AMTP --> TOTAL
    MTP --> TOTAL
    NGRAM --> TOTAL
    IMMED --> TOTAL
    MOE --> TOTAL
    ADV --> TOTAL

    TOTAL --> DETAIL

    style UL fill:#e3f2fd
    style DS fill:#c8e6c9
    style TOTAL fill:#fff3e0
    style DETAIL fill:#f3e5f5
```

### Component Hierarchy

```mermaid
graph LR
    subgraph "UnifiedLoss Architecture"
        Root[UnifiedLoss]

        Root --> Primary[Primary Loss<br/>Required]
        Root --> Optional[Optional Components<br/>Modular]

        Primary --> P1[Standard CE]
        Primary --> P2[DeepSeek ‚≠ê]
        Primary --> P3[Adaptive MTP]

        Optional --> O1[MTP Loss]
        Optional --> O2[Repetition Penalties]
        Optional --> O3[MoE Balancing]
        Optional --> O4[Advanced Losses]

        O2 --> R1[N-gram Penalty]
        O2 --> R2[Immediate Repetition]
        O2 --> R3[EOS Penalty]

        O4 --> A1[Focal Loss]
        O4 --> A2[Diversity Loss]
        O4 --> A3[Contrastive Loss]
        O4 --> A4[Auxiliary Losses]
    end

    style Root fill:#e3f2fd
    style Primary fill:#fff3e0
    style P2 fill:#c8e6c9
    style Optional fill:#f3e5f5
```

---

## Primary Loss Types

### Decision Tree: Choosing Primary Loss

```mermaid
flowchart TD
    Start([Choose Primary Loss]) --> Q1{Have MTP<br/>prediction heads?}

    Q1 -->|Yes| Q2{Need confidence<br/>weighting?}
    Q1 -->|No| Q3{Need advanced<br/>features?}

    Q2 -->|Yes| AMTP[üéØ Adaptive MTP<br/>primary_loss_type='adaptive_mtp']
    Q2 -->|No| DS2[üéØ DeepSeek + MTP<br/>primary_loss_type='deepseek'<br/>use_mtp=True]

    Q3 -->|Yes| DS[‚≠ê DeepSeek<br/>primary_loss_type='deepseek'<br/>RECOMMENDED]
    Q3 -->|No| STD[Standard CE<br/>primary_loss_type='standard'<br/>Simple & Fast]

    DS --> Features[+ Temperature scaling<br/>+ Label smoothing<br/>+ EOS penalties<br/>+ Adaptive temp]

    style Start fill:#e3f2fd
    style DS fill:#c8e6c9
    style AMTP fill:#fff3e0
    style DS2 fill:#c8e6c9
    style Features fill:#f3e5f5
```

### 1. Standard Cross-Entropy

**When to use**: Baseline training, fast prototyping, simple models

```python
loss_fn = UnifiedLoss(
    vocab_size=50257,
    primary_loss_type="standard",
    label_smoothing=0.0  # Optional smoothing
)
```

**Features**:
- ‚úÖ Fast and simple
- ‚úÖ Minimal overhead
- ‚úÖ Well-understood behavior
- ‚ùå No advanced features

### 2. DeepSeek-Style Loss ‚≠ê **RECOMMENDED**

**When to use**: Production training, models prone to repetition, need for stability

```python
loss_fn = UnifiedLoss(
    vocab_size=50257,
    primary_loss_type="deepseek",
    initial_temperature=1.0,
    adaptive_temperature=True,
    label_smoothing=0.1,
    eos_penalty_weight=0.05
)
```

**Features**:
- ‚úÖ Temperature-scaled cross-entropy
- ‚úÖ Adaptive temperature adjustment
- ‚úÖ Label smoothing
- ‚úÖ Early EOS penalties
- ‚úÖ Better gradient flow
- ‚úÖ Improved training stability

### 3. Adaptive MTP Loss

**When to use**: Models with multi-token prediction heads, need confidence weighting

```python
loss_fn = UnifiedLoss(
    vocab_size=50257,
    hidden_size=768,
    primary_loss_type="adaptive_mtp",
    adaptive_threshold=0.7,
    adaptive_weight_range=(0.5, 1.5)
)
```

**Features**:
- ‚úÖ Confidence-weighted predictions
- ‚úÖ Adaptive loss scaling
- ‚úÖ Best for MTP-enabled models
- ‚ö†Ô∏è Requires hidden states input
- ‚ö†Ô∏è Higher computational cost

---

## Loss Components

### Multi-Token Prediction (MTP)

Predicts multiple future tokens simultaneously for better context learning.

```mermaid
flowchart LR
    subgraph "Multi-Token Prediction Flow"
        H[Hidden States<br/>batch, seq_len, hidden] --> P1[Project Token+1]
        H --> P2[Project Token+2]
        H --> P3[Project Token+3]

        P1 --> L1[CE Loss 1]
        P2 --> L2[CE Loss 2]
        P3 --> L3[CE Loss 3]

        L1 --> AVG[Average<br/>MTP Loss]
        L2 --> AVG
        L3 --> AVG

        T1[Target Token+1] -.-> L1
        T2[Target Token+2] -.-> L2
        T3[Target Token+3] -.-> L3

        AVG --> W[Weighted<br/>* mtp_weight]
        W --> OUT[MTP Loss<br/>Component]
    end

    style H fill:#e3f2fd
    style AVG fill:#fff3e0
    style OUT fill:#c8e6c9
```

**Configuration**:
```python
loss_fn = UnifiedLoss(
    vocab_size=50257,
    hidden_size=768,
    use_mtp=True,
    num_future_tokens=3,      # Predict 1-3 tokens ahead
    mtp_type="deepseek",       # or "adaptive"
    mtp_weight=0.1             # Weight relative to main loss
)
```

**Usage**:
```python
# Must provide hidden_states
loss = loss_fn(
    logits=outputs.logits,
    targets=batch['labels'],
    hidden_states=outputs.hidden_states[-1]  # Last layer hidden states
)
```

### Repetition Penalties

Prevents mode collapse and repetitive text generation.

```mermaid
flowchart TD
    subgraph "Repetition Penalty System"
        IN[Input Logits<br/>& Target IDs]

        IN --> NG[N-gram Analysis]
        IN --> IM[Immediate Check]
        IN --> EOS[EOS Position Check]

        NG --> NGC{N-gram<br/>repeated?}
        NGC -->|Yes| NGP[Apply N-gram<br/>Penalty]
        NGC -->|No| NGS[Skip]

        IM --> IMC{Token = prev<br/>token?}
        IMC -->|Yes| IMP[Apply Immediate<br/>Penalty]
        IMC -->|No| IMS[Skip]

        EOS --> EOSC{EOS before<br/>min length?}
        EOSC -->|Yes| EOSP[Apply EOS<br/>Penalty]
        EOSC -->|No| EOSS[Skip]

        NGP --> SUM[Sum Penalties]
        IMP --> SUM
        EOSP --> SUM
        NGS --> SUM
        IMS --> SUM
        EOSS --> SUM

        SUM --> TOTAL[Total Repetition<br/>Penalty]
    end

    style IN fill:#e3f2fd
    style NGC fill:#fff9c4
    style IMC fill:#fff9c4
    style EOSC fill:#fff9c4
    style TOTAL fill:#c8e6c9
```

#### N-gram Repetition Penalty

Detects and penalizes repeated n-grams (e.g., "the the the").

```python
loss_fn = UnifiedLoss(
    vocab_size=50257,
    use_ngram_penalty=True,
    ngram_size=4,                  # Check 4-grams
    ngram_penalty_weight=0.1,      # Penalty strength
    ngram_window_size=50           # Look-back window
)
```

#### Immediate Repetition Penalty

Penalizes consecutive identical tokens (e.g., "time time time").

```python
loss_fn = UnifiedLoss(
    vocab_size=50257,
    use_immediate_repetition_penalty=True,
    immediate_repetition_weight=0.5,
    immediate_repetition_threshold=2  # Trigger after 2 repeats
)
```

#### Early EOS Penalty

Prevents premature sequence termination.

```python
loss_fn = UnifiedLoss(
    vocab_size=50257,
    eos_token_id=50256,
    min_sequence_length=20,        # Don't allow EOS before position 20
    eos_penalty_weight=0.05
)
```

### MoE Load Balancing

Auxiliary-free gradient-based expert balancing for Mixture-of-Experts models.

```mermaid
flowchart TD
    subgraph "MoE Load Balancing Flow"
        G[Gate Logits<br/>batch, seq_len, num_experts] --> S[Softmax<br/>Expert Probs]

        S --> U[Compute<br/>Expert Usage]
        S --> V[Compute<br/>Usage Variance]

        U --> T{Usage<br/>balanced?}
        V --> T

        T -->|No| BAL[Gradient Balance<br/>Loss]
        T -->|Yes| OK[Minimal Penalty]

        E[Expert Indices] --> COUNT[Count Expert<br/>Selections]
        O[Expert Outputs] --> DIV[Compute Output<br/>Diversity]

        COUNT --> BAL
        DIV --> BAL

        BAL --> W[Weighted<br/>* gradient_balance_weight]
        OK --> W

        W --> OUT[MoE Balance<br/>Loss]
    end

    style G fill:#e3f2fd
    style T fill:#fff9c4
    style BAL fill:#fff3e0
    style OUT fill:#c8e6c9
```

**Configuration**:
```python
loss_fn = UnifiedLoss(
    vocab_size=50257,
    num_experts=8,
    use_moe_balancing=True,
    gradient_balance_weight=0.1,
    target_expert_usage=0.125  # 1/8 for 8 experts
)
```

**Usage**:
```python
# Pass MoE-specific outputs
loss = loss_fn(
    logits=outputs.logits,
    targets=batch['labels'],
    gate_logits=outputs.gate_logits,      # Router gate logits
    expert_indices=outputs.expert_indices, # Selected experts
    expert_outputs=outputs.expert_outputs  # Expert outputs
)
```

### Advanced Losses

Additional loss components for specialized training scenarios.

```mermaid
graph TB
    subgraph "Advanced Loss Components"
        ADV[Advanced Losses]

        ADV --> F[Focal Loss<br/>Handle class imbalance]
        ADV --> D[Diversity Loss<br/>Encourage varied outputs]
        ADV --> C[Contrastive Loss<br/>Distinguish similar examples]
        ADV --> A[Auxiliary Losses<br/>Additional objectives]

        F --> FD[Focus on<br/>hard examples]
        D --> DD[Penalize<br/>uniform distributions]
        C --> CD[Maximize distance<br/>between classes]
        A --> AD[Task-specific<br/>objectives]
    end

    style ADV fill:#e3f2fd
    style F fill:#fff3e0
    style D fill:#f3e5f5
    style C fill:#fff9c4
    style A fill:#e1f5fe
```

**Configuration**:
```python
loss_fn = UnifiedLoss(
    vocab_size=50257,
    use_focal_loss=True,
    focal_gamma=2.0,              # Focus factor
    use_diversity_loss=True,
    diversity_weight=0.05,
    use_contrastive_loss=True,
    contrastive_temperature=0.07
)
```

---

## UnifiedLoss Composition

### Complete Loss Computation Flow

```mermaid
flowchart TD
    subgraph "UnifiedLoss Forward Pass"
        Start([Input: logits,<br/>targets, kwargs]) --> Check{Check inputs<br/>& masks}

        Check -->|Valid| Primary[Compute Primary Loss<br/>standard/deepseek/adaptive_mtp]
        Check -->|Invalid| Error[Raise ValueError]

        Primary --> Init[Initialize<br/>total_loss = primary_loss]

        Init --> MTPCheck{use_mtp<br/>enabled?}
        MTPCheck -->|Yes| MTPComp[Compute MTP Loss<br/>+ Add to total]
        MTPCheck -->|No| NGCheck
        MTPComp --> NGCheck

        NGCheck{use_ngram_penalty<br/>enabled?}
        NGCheck -->|Yes| NGComp[Compute N-gram Penalty<br/>+ Add to total]
        NGCheck -->|No| IMCheck
        NGComp --> IMCheck

        IMCheck{use_immediate_repetition<br/>enabled?}
        IMCheck -->|Yes| IMComp[Compute Immediate Penalty<br/>+ Add to total]
        IMCheck -->|No| MOECheck
        IMComp --> MOECheck

        MOECheck{use_moe_balancing<br/>enabled?}
        MOECheck -->|Yes| MOEComp[Compute MoE Balance<br/>+ Add to total]
        MOECheck -->|No| AdvCheck
        MOEComp --> AdvCheck

        AdvCheck{Advanced losses<br/>enabled?}
        AdvCheck -->|Yes| AdvComp[Compute Advanced Losses<br/>+ Add to total]
        AdvCheck -->|No| Return
        AdvComp --> Return

        Return{return_detailed?}
        Return -->|Yes| RetDict[Return loss_dict<br/>with breakdown]
        Return -->|No| RetScalar[Return total_loss<br/>scalar tensor]
    end

    style Start fill:#e3f2fd
    style Primary fill:#fff3e0
    style Init fill:#c8e6c9
    style RetDict fill:#f3e5f5
    style RetScalar fill:#c8e6c9
    style Check fill:#fff9c4
    style MTPCheck fill:#fff9c4
    style NGCheck fill:#fff9c4
    style IMCheck fill:#fff9c4
    style MOECheck fill:#fff9c4
    style AdvCheck fill:#fff9c4
```

### Loss Weighting & Combination

```mermaid
flowchart LR
    subgraph "Loss Component Weighting"
        P[Primary Loss<br/>weight = 1.0] --> T[Total Loss]
        M[MTP Loss<br/>weight = 0.1] --> T
        N[N-gram Penalty<br/>weight = 0.1] --> T
        I[Immediate Penalty<br/>weight = 0.5] --> T
        O[MoE Balance<br/>weight = 0.1] --> T
        F[Focal Loss<br/>weight = 0.2] --> T
        D[Diversity Loss<br/>weight = 0.05] --> T

        T --> Formula["Total = Œ£ (component √ó weight)"]
        Formula --> Out[Final Loss Tensor]
    end

    style P fill:#c8e6c9
    style T fill:#fff3e0
    style Out fill:#e3f2fd
```

**Default Weights** (recommended starting points):

| Component | Default Weight | Range | Purpose |
|-----------|---------------|-------|---------|
| Primary Loss | 1.0 | Fixed | Main training objective |
| MTP Loss | 0.1 | 0.05-0.3 | Future token prediction |
| N-gram Penalty | 0.1 | 0.05-0.2 | Prevent repetitive n-grams |
| Immediate Penalty | 0.5 | 0.2-1.0 | Prevent token repetition |
| EOS Penalty | 0.05 | 0.01-0.1 | Prevent premature ending |
| MoE Balance | 0.1 | 0.05-0.2 | Expert load balancing |
| Focal Loss | 0.2 | 0.1-0.5 | Handle hard examples |
| Diversity Loss | 0.05 | 0.01-0.1 | Encourage variety |

---

## Loss Computation Flow

### Detailed Forward Pass

```mermaid
sequenceDiagram
    participant T as Training Loop
    participant UL as UnifiedLoss
    participant P as Primary Loss
    participant C as Components
    participant O as Output

    T->>UL: forward(logits, targets, kwargs)

    UL->>UL: Validate inputs
    UL->>UL: Apply attention mask

    UL->>P: Compute primary loss
    alt Standard CE
        P-->>UL: standard_ce_loss
    else DeepSeek
        P-->>UL: deepseek_loss
    else Adaptive MTP
        P-->>UL: adaptive_mtp_loss
    end

    UL->>UL: Initialize total_loss

    opt MTP Enabled
        UL->>C: Compute MTP loss
        C-->>UL: mtp_loss
        UL->>UL: total_loss += mtp_loss
    end

    opt N-gram Penalty Enabled
        UL->>C: Compute n-gram penalty
        C-->>UL: ngram_penalty
        UL->>UL: total_loss += ngram_penalty
    end

    opt Immediate Repetition Enabled
        UL->>C: Compute immediate penalty
        C-->>UL: immediate_penalty
        UL->>UL: total_loss += immediate_penalty
    end

    opt MoE Balancing Enabled
        UL->>C: Compute MoE balance loss
        C-->>UL: moe_balance_loss
        UL->>UL: total_loss += moe_balance_loss
    end

    opt Advanced Losses Enabled
        UL->>C: Compute advanced losses
        C-->>UL: advanced_losses
        UL->>UL: total_loss += advanced_losses
    end

    alt return_detailed=True
        UL->>O: Return detailed loss_dict
        O-->>T: {total_loss, main_loss, mtp_loss, ...}
    else return_detailed=False
        UL->>O: Return total_loss
        O-->>T: total_loss (scalar tensor)
    end

    T->>T: total_loss.backward()
```

### Backward Pass & Gradient Flow

```mermaid
flowchart RL
    subgraph "Gradient Backward Pass"
        Loss[Total Loss<br/>Scalar] --> Grad[Compute Gradients<br/>loss.backward]

        Grad --> GP[Primary Loss<br/>‚àÇL/‚àÇŒ∏_primary]
        Grad --> GM[MTP Loss<br/>‚àÇL/‚àÇŒ∏_mtp]
        Grad --> GN[N-gram Penalty<br/>‚àÇL/‚àÇŒ∏_ngram]
        Grad --> GI[Immediate Penalty<br/>‚àÇL/‚àÇŒ∏_immediate]
        Grad --> GO[MoE Balance<br/>‚àÇL/‚àÇŒ∏_moe]

        GP --> Model[Model Parameters Œ∏]
        GM --> Model
        GN --> Model
        GI --> Model
        GO --> Model

        Model --> Update[Optimizer.step<br/>Update Parameters]
    end

    style Loss fill:#e3f2fd
    style Grad fill:#fff3e0
    style Model fill:#f3e5f5
    style Update fill:#c8e6c9
```

---

## Configuration Guide

### Configuration Decision Tree

```mermaid
flowchart TD
    Start([Configure<br/>UnifiedLoss]) --> Task{Training<br/>Task?}

    Task -->|Standard LLM| Std[Standard Configuration]
    Task -->|MoE Model| Moe[MoE Configuration]
    Task -->|Repetition Issues| Rep[Anti-Repetition Configuration]
    Task -->|Research/Custom| Cust[Custom Configuration]

    Std --> StdConf["primary_loss_type='deepseek'<br/>label_smoothing=0.1<br/>use_ngram_penalty=True<br/>use_immediate_repetition=True"]

    Moe --> MoeConf["num_experts=8<br/>use_moe_balancing=True<br/>use_diversity_loss=True<br/>gradient_balance_weight=0.1"]

    Rep --> RepConf["ngram_penalty_weight=0.2<br/>immediate_repetition_weight=1.0<br/>eos_penalty_weight=0.1<br/>min_sequence_length=30"]

    Cust --> CustConf[Start simple,<br/>add components<br/>incrementally]

    style Start fill:#e3f2fd
    style Std fill:#c8e6c9
    style Moe fill:#fff3e0
    style Rep fill:#f3e5f5
```

### Standard LLM Training

```python
from Ava.losses import UnifiedLoss

loss_fn = UnifiedLoss(
    vocab_size=50257,
    primary_loss_type="deepseek",      # ‚≠ê Recommended

    # Temperature & smoothing
    initial_temperature=1.0,
    adaptive_temperature=True,
    label_smoothing=0.1,

    # Repetition prevention
    use_ngram_penalty=True,
    ngram_penalty_weight=0.1,
    use_immediate_repetition_penalty=True,
    immediate_repetition_weight=0.5,

    # EOS handling
    eos_token_id=tokenizer.eos_token_id,
    pad_token_id=tokenizer.pad_token_id,
    min_sequence_length=20,
    eos_penalty_weight=0.05
)
```

### MoE Model Training

```python
loss_fn = UnifiedLoss(
    vocab_size=50257,
    hidden_size=768,
    num_experts=8,

    # MoE-specific
    use_moe_balancing=True,
    gradient_balance_weight=0.1,
    target_expert_usage=0.125,  # 1/num_experts

    # Encourage diversity
    use_diversity_loss=True,
    diversity_weight=0.05,

    # Standard features
    primary_loss_type="deepseek",
    use_ngram_penalty=True
)

# Usage in training loop
outputs = model(**batch, output_hidden_states=True)
loss = loss_fn(
    logits=outputs.logits,
    targets=batch['labels'],
    gate_logits=outputs.gate_logits,      # MoE gates
    expert_indices=outputs.expert_indices, # Selected experts
    expert_outputs=outputs.expert_outputs  # Expert outputs
)
```

### Anti-Repetition Focus

```python
loss_fn = UnifiedLoss(
    vocab_size=50257,
    primary_loss_type="deepseek",

    # Strong repetition penalties
    use_ngram_penalty=True,
    ngram_size=4,
    ngram_penalty_weight=0.2,        # Higher weight
    ngram_window_size=100,

    use_immediate_repetition_penalty=True,
    immediate_repetition_weight=1.0,  # Much higher
    immediate_repetition_threshold=2,

    # Prevent early EOS
    eos_token_id=tokenizer.eos_token_id,
    min_sequence_length=30,           # Longer minimum
    eos_penalty_weight=0.1,

    # Temperature control
    initial_temperature=1.2,          # Slightly higher
    adaptive_temperature=True
)
```

### Multi-Token Prediction (MTP)

```python
loss_fn = UnifiedLoss(
    vocab_size=50257,
    hidden_size=768,
    primary_loss_type="deepseek",

    # Enable MTP
    use_mtp=True,
    num_future_tokens=3,
    mtp_type="deepseek",  # or "adaptive"
    mtp_weight=0.1,

    # Standard components
    use_ngram_penalty=True,
    eos_token_id=tokenizer.eos_token_id
)

# Must provide hidden states
outputs = model(**batch, output_hidden_states=True)
loss = loss_fn(
    logits=outputs.logits,
    targets=batch['labels'],
    hidden_states=outputs.hidden_states[-1],  # Required for MTP
    attention_mask=batch.get('attention_mask')
)
```

---

## Use Cases & Examples

### Training Loop Integration

```python
from Ava.losses import UnifiedLoss
import torch

# Initialize loss function
loss_fn = UnifiedLoss(
    vocab_size=config.vocab_size,
    hidden_size=config.hidden_size,
    primary_loss_type="deepseek",
    use_mtp=config.use_mtp,
    use_ngram_penalty=True,
    eos_token_id=tokenizer.eos_token_id,
    pad_token_id=tokenizer.pad_token_id
)

# Training loop
for epoch in range(num_epochs):
    for batch in dataloader:
        optimizer.zero_grad()

        # Forward pass
        outputs = model(**batch, output_hidden_states=config.use_mtp)

        # Compute loss
        loss = loss_fn(
            logits=outputs.logits,
            targets=batch['labels'],
            attention_mask=batch.get('attention_mask'),
            hidden_states=outputs.hidden_states[-1] if config.use_mtp else None
        )

        # Backward pass
        loss.backward()

        # Gradient clipping (recommended)
        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)

        # Optimizer step
        optimizer.step()
        scheduler.step()

        # Logging
        if step % log_interval == 0:
            print(f"Step {step}, Loss: {loss.item():.4f}")
```

### Detailed Loss Monitoring

```python
# Get detailed breakdown
loss_dict = loss_fn(
    logits=outputs.logits,
    targets=batch['labels'],
    attention_mask=batch['attention_mask'],
    hidden_states=outputs.hidden_states[-1],
    return_detailed=True  # Return dictionary instead of scalar
)

# Access individual components
print(f"Main Loss: {loss_dict['main_loss'].item():.4f}")
print(f"MTP Loss: {loss_dict.get('mtp_loss', torch.tensor(0.0)).item():.4f}")
print(f"N-gram Penalty: {loss_dict.get('ngram_penalty', torch.tensor(0.0)).item():.4f}")
print(f"Immediate Penalty: {loss_dict.get('immediate_repetition_penalty', torch.tensor(0.0)).item():.4f}")
print(f"Total Loss: {loss_dict['total_loss'].item():.4f}")

# Backward on total loss
loss_dict['total_loss'].backward()

# Log to tensorboard/wandb
logger.log({
    'loss/main': loss_dict['main_loss'].item(),
    'loss/mtp': loss_dict.get('mtp_loss', torch.tensor(0.0)).item(),
    'loss/ngram': loss_dict.get('ngram_penalty', torch.tensor(0.0)).item(),
    'loss/total': loss_dict['total_loss'].item()
})
```

### Hyperparameter Tuning

```python
import optuna

def objective(trial):
    # Suggest hyperparameters
    ngram_weight = trial.suggest_float('ngram_weight', 0.05, 0.3)
    immediate_weight = trial.suggest_float('immediate_weight', 0.2, 1.5)
    temperature = trial.suggest_float('temperature', 0.8, 1.5)

    # Create loss function
    loss_fn = UnifiedLoss(
        vocab_size=50257,
        primary_loss_type="deepseek",
        initial_temperature=temperature,
        ngram_penalty_weight=ngram_weight,
        immediate_repetition_weight=immediate_weight,
        use_ngram_penalty=True,
        use_immediate_repetition_penalty=True
    )

    # Train and return validation loss
    val_loss = train_and_evaluate(model, loss_fn, train_loader, val_loader)
    return val_loss

# Run optimization
study = optuna.create_study(direction='minimize')
study.optimize(objective, n_trials=50)

print(f"Best hyperparameters: {study.best_params}")
```

---

## Performance Considerations

### Computational Overhead

```mermaid
graph LR
    subgraph "Relative Computational Cost"
        Base[Standard CE<br/>Baseline: 1.0x]
        DS[DeepSeek<br/>~1.02x]
        MTP[+ MTP<br/>~1.08x]
        NG[+ N-gram<br/>~1.03x]
        IM[+ Immediate<br/>~1.01x]
        MOE[+ MoE Balance<br/>~1.05x]
        All[All Features<br/>~1.10x]
    end

    Base --> DS
    DS --> MTP
    MTP --> NG
    NG --> IM
    IM --> MOE
    MOE --> All

    style Base fill:#c8e6c9
    style DS fill:#c8e6c9
    style MTP fill:#fff9c4
    style All fill:#ffccbc
```

**Key Insights**:
- ‚úÖ Minimal overhead for most components (<5%)
- ‚ö†Ô∏è MTP has highest cost (~8% slower)
- ‚úÖ Repetition penalties are very cheap (~1-3%)
- ‚úÖ Total overhead with all features: ~10%

### Memory Usage

| Component | Memory Overhead | Notes |
|-----------|----------------|-------|
| Standard CE | Baseline | Reference point |
| DeepSeek | +0.5% | Temperature buffer only |
| MTP | +5-10% | Projection heads + intermediate tensors |
| N-gram Penalty | +1% | Small buffers for n-gram tracking |
| Immediate Penalty | <0.1% | Negligible |
| MoE Balancing | +2% | Expert statistics |
| **Total (all features)** | **+8-15%** | Acceptable for most setups |

### Optimization Tips

```mermaid
flowchart TD
    Start([Performance<br/>Optimization]) --> Q1{Memory<br/>constrained?}

    Q1 -->|Yes| Mem[Reduce Memory Usage]
    Q1 -->|No| Q2{Speed<br/>constrained?}

    Mem --> M1[Disable MTP]
    Mem --> M2[Use shared_projection=True]
    Mem --> M3[Reduce num_future_tokens]

    Q2 -->|Yes| Speed[Improve Speed]
    Q2 -->|No| Q3{Want detailed<br/>monitoring?}

    Speed --> S1[Disable advanced losses]
    Speed --> S2[Reduce ngram_window_size]
    Speed --> S3[Use primary='standard']

    Q3 -->|Yes| Mon[Enable Monitoring]
    Q3 -->|No| Done[Optimal Config]

    Mon --> MN1[Use return_detailed=True]
    Mon --> MN2[Log component losses]
    Mon --> MN3[Track component trends]

    M1 --> Done
    M2 --> Done
    M3 --> Done
    S1 --> Done
    S2 --> Done
    S3 --> Done
    MN1 --> Done
    MN2 --> Done
    MN3 --> Done

    style Start fill:#e3f2fd
    style Done fill:#c8e6c9
    style Mem fill:#fff9c4
    style Speed fill:#fff9c4
    style Mon fill:#f3e5f5
```

### Distributed Training Compatibility

| Framework | Compatible | Notes |
|-----------|-----------|-------|
| PyTorch DDP | ‚úÖ Yes | Fully supported |
| FSDP | ‚úÖ Yes | Works seamlessly |
| DeepSpeed ZeRO-1 | ‚úÖ Yes | No issues |
| DeepSpeed ZeRO-2 | ‚úÖ Yes | No issues |
| DeepSpeed ZeRO-3 | ‚úÖ Yes | May need small adjustments for MTP |
| Gradient Accumulation | ‚úÖ Yes | Fully compatible |
| Mixed Precision (AMP) | ‚úÖ Yes | Recommended |
| bfloat16 | ‚úÖ Yes | Best option |

---

## Troubleshooting

### Common Issues & Solutions

```mermaid
flowchart TD
    subgraph "Troubleshooting Decision Tree"
        Issue([Issue<br/>Encountered]) --> Type{Issue<br/>Type?}

        Type -->|Loss NaN/Inf| NaN[NaN/Inf Issues]
        Type -->|Poor Convergence| Conv[Convergence Issues]
        Type -->|Memory Error| Mem[Memory Issues]
        Type -->|Slow Training| Speed[Speed Issues]

        NaN --> N1[Check learning rate<br/>too high?]
        NaN --> N2[Enable gradient clipping<br/>max_norm=1.0]
        NaN --> N3[Reduce temperature<br/>start with 1.0]
        NaN --> N4[Check for invalid inputs<br/>NaN in data]

        Conv --> C1[Increase penalty weights<br/>if repetitive]
        Conv --> C2[Add label smoothing<br/>0.05-0.15]
        Conv --> C3[Enable adaptive temperature]
        Conv --> C4[Try DeepSeek loss]

        Mem --> M1[Disable MTP<br/>use_mtp=False]
        Mem --> M2[Reduce num_future_tokens]
        Mem --> M3[Use gradient checkpointing]

        Speed --> S1[Disable advanced losses]
        Speed --> S2[Reduce ngram_window_size]
        Speed --> S3[Use standard CE<br/>if speed critical]
    end

    style Issue fill:#e3f2fd
    style NaN fill:#ffccbc
    style Conv fill:#fff9c4
    style Mem fill:#fff3e0
    style Speed fill:#f3e5f5
```

### NaN/Inf Loss Values

**Symptoms**: Loss becomes NaN or Inf during training

**Causes & Solutions**:

1. **Learning rate too high**
   ```python
   # Reduce learning rate
   optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)  # Lower LR
   ```

2. **Missing gradient clipping**
   ```python
   # Add gradient clipping
   loss.backward()
   torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
   optimizer.step()
   ```

3. **Temperature too low/high**
   ```python
   # Use safe temperature bounds
   loss_fn = UnifiedLoss(
       vocab_size=50257,
       initial_temperature=1.0,  # Start at 1.0
       temperature_bounds=(0.7, 1.5)  # Narrow bounds
   )
   ```

4. **Invalid inputs**
   ```python
   # Check for NaN in inputs
   assert not torch.isnan(logits).any(), "NaN in logits"
   assert not torch.isnan(targets).any(), "NaN in targets"
   ```

### Poor Convergence / High Loss

**Symptoms**: Loss plateaus or doesn't decrease

**Solutions**:

1. **Enable more loss components**
   ```python
   loss_fn = UnifiedLoss(
       vocab_size=50257,
       primary_loss_type="deepseek",  # Switch to DeepSeek
       label_smoothing=0.1,            # Add smoothing
       use_ngram_penalty=True,         # Add penalties
       adaptive_temperature=True       # Enable adaptation
   )
   ```

2. **Increase penalty weights** (if model is repetitive)
   ```python
   loss_fn = UnifiedLoss(
       vocab_size=50257,
       ngram_penalty_weight=0.2,        # Increase from 0.1
       immediate_repetition_weight=1.0  # Increase from 0.5
   )
   ```

3. **Monitor component contributions**
   ```python
   # Use detailed breakdown to identify issues
   loss_dict = loss_fn(..., return_detailed=True)

   # Check if any component is dominating
   for key, value in loss_dict.items():
       if isinstance(value, torch.Tensor):
           print(f"{key}: {value.item():.4f}")
   ```

### Memory Errors (OOM)

**Symptoms**: CUDA out of memory errors

**Solutions**:

1. **Disable MTP** (biggest memory consumer)
   ```python
   loss_fn = UnifiedLoss(
       vocab_size=50257,
       use_mtp=False  # Saves 5-10% memory
   )
   ```

2. **Reduce future token predictions**
   ```python
   loss_fn = UnifiedLoss(
       vocab_size=50257,
       use_mtp=True,
       num_future_tokens=2,  # Reduce from 3 to 2
       shared_projection=True  # Share projection heads
   )
   ```

3. **Use gradient checkpointing**
   ```python
   # Enable in model
   model.gradient_checkpointing_enable()
   ```

4. **Reduce batch size or sequence length**

### Slow Training Speed

**Symptoms**: Training is slower than expected

**Solutions**:

1. **Profile components**
   ```python
   import time

   start = time.time()
   loss = loss_fn(logits, targets)
   print(f"Loss computation: {time.time() - start:.4f}s")
   ```

2. **Disable expensive components**
   ```python
   loss_fn = UnifiedLoss(
       vocab_size=50257,
       use_mtp=False,           # Disable MTP (8% speedup)
       use_focal_loss=False,    # Disable focal loss
       use_diversity_loss=False # Disable diversity loss
   )
   ```

3. **Reduce n-gram window size**
   ```python
   loss_fn = UnifiedLoss(
       vocab_size=50257,
       use_ngram_penalty=True,
       ngram_window_size=30  # Reduce from 50
   )
   ```

4. **Use standard CE for maximum speed**
   ```python
   loss_fn = UnifiedLoss(
       vocab_size=50257,
       primary_loss_type="standard",  # Fastest option
       use_ngram_penalty=True,        # Keep only cheap penalties
       use_immediate_repetition_penalty=True
   )
   ```

### Repetitive Outputs

**Symptoms**: Model generates repetitive text

**Solutions**:

1. **Strengthen repetition penalties**
   ```python
   loss_fn = UnifiedLoss(
       vocab_size=50257,
       use_ngram_penalty=True,
       ngram_penalty_weight=0.3,        # Much higher
       use_immediate_repetition_penalty=True,
       immediate_repetition_weight=1.5, # Much higher
       eos_penalty_weight=0.15          # Prevent early exit
   )
   ```

2. **Increase minimum sequence length**
   ```python
   loss_fn = UnifiedLoss(
       vocab_size=50257,
       min_sequence_length=50,  # Longer sequences
       eos_penalty_weight=0.1
   )
   ```

3. **Use diversity loss**
   ```python
   loss_fn = UnifiedLoss(
       vocab_size=50257,
       use_diversity_loss=True,
       diversity_weight=0.1  # Encourage varied outputs
   )
   ```

---

## Additional Resources

### Related Documentation

- **[LOSSES_README.md](LOSSES_README.md)** - Quick reference guide
- **[LOSSES_USAGE_GUIDE.md](LOSSES_USAGE_GUIDE.md)** - Comprehensive usage examples
- **[02_TRAINING_GUIDE.md](02_TRAINING_GUIDE.md)** - Training pipeline integration
- **[FLOWCHARTS_VISUAL.md](FLOWCHARTS_VISUAL.md)** - Visual training flowcharts

### Source Code

- **[losses.py](../src/Ava/losses/losses.py)** - Complete loss implementations
- **[__init__.py](../src/Ava/losses/__init__.py)** - Module exports
- **[test_unified_loss.py](../tests/test_unified_loss.py)** - Test suite

### Testing

Run the test suite to verify your loss configuration:

```bash
cd /project/code
python tests/test_unified_loss.py
```

All tests should pass with "All tests passed! ‚úì"

---

## Summary

### Key Takeaways

1. ‚≠ê **Use DeepSeek loss** as the primary loss type for most applications
2. üß© **Enable components incrementally** - start simple, add features as needed
3. üìä **Monitor component contributions** with `return_detailed=True`
4. ‚ö° **Minimal overhead** - only ~10% slower with all features
5. üîß **Highly tunable** - adjust weights based on your specific problem
6. üöÄ **Distributed-ready** - works with DDP, FSDP, DeepSpeed
7. üéØ **Prevention is key** - use repetition penalties to avoid mode collapse

### Quick Configuration Matrix

| Use Case | Primary Loss | Key Components | Priority Features |
|----------|-------------|----------------|-------------------|
| **Standard LLM** | `deepseek` | N-gram, Immediate penalties | Temperature, Label smoothing |
| **MoE Model** | `deepseek` | MoE balancing, Diversity | Gradient balance, Expert usage |
| **Repetition Issues** | `deepseek` | Strong penalties, EOS control | Higher weights, Longer min length |
| **MTP Model** | `adaptive_mtp` | MTP loss, Future prediction | Confidence weighting, MTP heads |
| **Fast Prototyping** | `standard` | None (optional penalties) | Simple CE, Minimal overhead |
| **Production** | `deepseek` | N-gram, Immediate, EOS | All stability features |

---

**Last Updated**: 2025-11-03
**Version**: 1.0.0
**Maintainer**: Ava AI Team
